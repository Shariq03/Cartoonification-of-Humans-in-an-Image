{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cartoonizer:\n",
    "    \"\"\"Cartoonizer effect\n",
    "        A class that applies a cartoon effect to an image.\n",
    "        The class uses a bilateral filter and adaptive thresholding to create\n",
    "        a cartoon effect.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def render(self, img_rgb):\n",
    "        img_rgb = cv2.imread(img_rgb)\n",
    "        numDownSamples = 2      # number of downscaling steps\n",
    "        numBilateralFilters = 5  # number of bilateral filtering steps\n",
    "\n",
    "        '''\n",
    "        STEP 1 : \n",
    "        '''\n",
    "        # Downsample image using Gaussian pyramid\n",
    "        img_color = img_rgb\n",
    "        for _ in range(numDownSamples):\n",
    "            img_color = cv2.pyrDown(img_color)\n",
    "        \n",
    "        # Repeatedly apply small bilateral filter instead of applying one large filter\n",
    "        for _ in range(numBilateralFilters):\n",
    "            img_color = cv2.bilateralFilter(img_color, d=7,sigmaColor=9,sigmaSpace=9)\n",
    "        \n",
    "        # Upsample image to original size\n",
    "        for _ in range(numDownSamples):\n",
    "            img_color = cv2.pyrUp(img_color)\n",
    "        \n",
    "        '''\n",
    "        STEP 2 AND 3\n",
    "        '''\n",
    "        # Convert to grayscale and apply median blur\n",
    "        img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "        img_blur = cv2.medianBlur(img_gray, 3)\n",
    "        \n",
    "        '''\n",
    "        STEP 4\n",
    "        '''\n",
    "        # Detect and enhance edges\n",
    "        img_edge = cv2.adaptiveThreshold(img_blur, 255,\n",
    "                                         cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                         cv2.THRESH_BINARY, \n",
    "                                         blockSize = 9, \n",
    "                                         C = 7)\n",
    "        \n",
    "        '''\n",
    "        STEP 5\n",
    "        '''\n",
    "        # Convert back to color so that it can be bit-ANDed with color image\n",
    "        (x,y,z) = img_color.shape\n",
    "        img_edge = cv2.resize(img_edge,(y,x)) \n",
    "        img_edge = cv2.cvtColor(img_edge, cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        return cv2.bitwise_and(img_color, img_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_path = os.getcwd()\n",
    "\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsRetinaNet()\n",
    "detector.setModelPath(os.path.join(execution_path , \"retinanet_best_coco.h5\"))\n",
    "detector.loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify input image name\n",
    "input_image_path = os.path.join('Input', 'APJ-Kalam.JPG')\n",
    "\n",
    "detections, extracted_images = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , input_image_path), extract_detected_objects=True)\n",
    "\n",
    "img = cv2.imread(input_image_path) \n",
    "tmp_canvas = Cartoonizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "l =[]\n",
    "\n",
    "for eachObject in detections:\n",
    "    i = i + 1\n",
    "    if(eachObject[\"name\"] == 'person'):\n",
    "        print(eachObject[\"name\"] , \" : \" , eachObject[\"percentage_probability\"])\n",
    "        print ('Top left and bottom right coordinates of bounding box are: ', l)\n",
    "        l = eachObject['box_points']\n",
    "        \n",
    "        object_img_path = eachObject[\"name\"]+'-'+str(i)+'.jpg'\n",
    "        crop_img = cv2.imread(\"-objects/\"+object_img_path)\n",
    "        cv2.imwrite('Output/crop_img'+str(i)+'.jpg', crop_img)\n",
    "        \n",
    "        result = tmp_canvas.render('Output/crop_img'+str(i)+'.jpg')\n",
    "        cv2.imwrite('Output/cartoon_version'+str(i)+'.jpg', result)\n",
    "        \n",
    "        img[l[1]: l[1]+ result.shape[0], l[0]: l[0]+ result.shape[1]] = result\n",
    "        cv2.imwrite('Output/final.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
